<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Rui Qian</title>
<meta name="author" content="Rui Qian">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Qian (钱锐)</name>
              </p>
              <p>I am a Ph.D. student in <a href="http://mmlab.ie.cuhk.edu.hk/">Multi-Media Lab</a> at The Chinese University of Hong Kong, supervised by <a href="http://dahua.site/">Prof. Dahua Lin</a>.
              </p>
              <p>
                I got my bachelor's degree from School of Electronic Information and Electrical Engineering at Shanghai Jiao Tong University in 2021, supervised by <a href="https://weiyaolin.github.io/">Prof. Weiyao Lin</a>. 
				During my undergraduate, I also interned at Sensetime OpenMMLab group, supervised by <a href="https://chenkai.site/">Dr. Kai Chen</a>.
				And I am also honored to work with <a href="https://dtaoo.github.io/">Prof. Di Hu</a>.
              </p>
              <p>
                I am interested in computer vision and machine learning, and have done some research on video representation learning and joint audio-visual learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:qr021@ie.cuhk.edu.hk">Email</a> &nbsp/&nbsp
                <a href="data/CV_RuiQian.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/shvdiwnkozbw">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/qianrui.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/qianrui.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>[2021-07]</strong> </b> One paper accepted to <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>.
              </p>
              <p>
                <strong>[2021-06]</strong> </b> Graduate from <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>.
              </p>
              <p>
                <strong>[2020-09]</strong> </b> One paper accepted to <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>.
              </p>
              <p>
                <strong>[2020-07]</strong> </b> One paper accepted to <a href="https://eccv2020.eu/">ECCV 2020</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	    <tr onmouseout="iccv_stop()" onmouseover="iccv_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='iccv_image'>
                  <img src='images/iccv2.JPG' width="200" height="120"></div>
                <img src='images/iccv.JPG' width="200" height="120">
              </div>
              <script type="text/javascript">
                function iccv_start() {
                  document.getElementById('iccv_image').style.opacity = "1";
                }

                function iccv_stop() {
                  document.getElementById('iccv_image').style.opacity = "0";
                }
                iccv_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2108.02183">
                <papertitle>Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization</papertitle>
              </a>
              <br>
			  <strong>Rui Qian</strong>,              
			  Yuxi Li,
			  Huabin Liu,
			  John See,
			  Shuangrui Ding,
			  Xian Liu,
			  Dian Li,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ICCV</em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2108.02183">arXiv</a>,
			  <a href="https://github.com/shvdiwnkozbw/Video-Representation-via-Multi-level-Optimization">code</a>
			  <p>Self-supervised video representation learning from the perspective of both high-level semantics and lower-level characteristics</p>
			  </td>
          </tr> 
	
	    <tr onmouseout="nips_stop()" onmouseover="nips_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nips_image'>
                  <img src='images/nips2.JPG' width="200" height="150"></div>
                <img src='images/nips.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function nips_start() {
                  document.getElementById('nips_image').style.opacity = "1";
                }

                function nips_stop() {
                  document.getElementById('nips_image').style.opacity = "0";
                }
                nips_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2010.05466">
                <papertitle>Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching</papertitle>
              </a>
              <br>
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  <strong>Rui Qian</strong>,              
			  Minyue Jiang,
			  Tan Xiao,
			  Shilei Wen,
			  Errui Ding,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Dejing Dou
              <br>
        <em>NeurIPS</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2010.05466">arXiv</a>,
			  <a href="https://github.com/DTaoo/Discriminative-Sounding-Objects-Localization">code</a>
			  <p>Discriminative sounding objects localization in cocktail-party scenario in a two-stage manner</p>
			  </td>
          </tr> 


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/eccv2.JPG' width="200" height="150"></div>
                <img src='images/eccv.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2007.06355">
                <papertitle>Multiple Sound Sources Localization from Coarse to Fine</papertitle>
              </a>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ECCV</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2007.06355">arXiv</a>,
			  <a href="https://github.com/shvdiwnkozbw/Multi-Source-Sound-Localization">code</a>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 

		  <tr onmouseout="kk_stop()" onmouseover="kk_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='kk_image'>
                  <img src='images/aaai2.JPG' width="200" height="150"></div>
                <img src='images/aaai.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function kk_start() {
                  document.getElementById('kk_image').style.opacity = "1";
                }

                function kk_stop() {
                  document.getElementById('kk_image').style.opacity = "0";
                }
                kk_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2008.13196">
                <papertitle>Finding Action Tubes with a Sparse-to-Dense Framework</papertitle>
              </a>
              <br>
			  Yuxi Li,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Tao Wang,
			  John See,
              <strong>Rui Qian</strong>,
			  Ning Xu,
			  Limin Wang,
			  Shugong Xu
              <br>
        <em>AAAI</em>, 2020  
              <p>Spatio-temporal action localization, to localize 3D action tubes in temporal and spatial domain</p>
			  </td>
          </tr> 

        </tbody></table>

<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Workshop Papers</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="cvpr_stop()" onmouseover="cvpr_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                  <img src='images/eccv.JPG' width="200" height="150"></div>
                <img src='images/eccv2.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function cvpr_start() {
                  document.getElementById('cvpr_image').style.opacity = "1";
                }

                function cvpr_stop() {
                  document.getElementById('cvpr_image').style.opacity = "0";
                }
                cvpr_stop()
              </script>
            </td>
	<td style="padding:20px;width:65%;vertical-align:middle">
              <a href="http://sightsound.org/papers/2020/Rui_Qian_A_Two-Stage_Framework_for_Multiple_Sound-Source_Localization.pdf">
                <papertitle>A Two-Stage Framework for Multiple Sound-Source Localization</papertitle>
              </a>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>CVPR Sight and Sound Workshop</em>, 2020  
              <br>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 
 -->		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <strong>Hong Kong PhD Fellowship Scheme</strong>. 2021
              </p>
              <p>
                <strong>Outstanding Graduate of Shanghai</strong>. 2021
              </p>
              <p>
                <strong>Top 1% Bachelor Thesis Award of Shanghai Jiao Tong University</strong>. 2021
              </p>
              <p>
                <strong>Sensetime Scholarship</strong>. 2020
              </p>
              <p>
                <strong>Finalist winner of MCM</strong>. 2019
              </p>
              <p>
              <strong>Nation Scholarship</strong>, Ministry of Education of China. 2018
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc</heading>
              <p>
                1. Great honor to be awarded the bachelor's degree from Shanghai Jiao Tong University, really memorable four years and great thanks for the friends, colleagues and professors.
              </p>
              <p>
                2. I am proud that I have graudated from the competition class at Hangzhou No.2 High school, where I make friends with so many talented students and prestigious teachers.
              </p>
			  <p>
				3. Here is my best friend <a href="https://mark12ding.github.io/">Shuangrui</a>, who is really talented and interesting. His wonderful work on adversarial attack on GNN was accepted to <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>!
			  </p>
            </td>
          </tr>
        </tbody></table>
    <p>Updated at Sep. 2020. Thanks <a href="https://jonbarron.info/"> Jon Barron</a> for this amazing template.</p>
    </body>
</html>
