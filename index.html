<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Rui Qian</title>
<meta name="author" content="Rui Qian">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Qian (钱锐)</name>
              </p>
              <p>I am a Ph.D. student in <a href="http://mmlab.ie.cuhk.edu.hk/">Multi-Media Lab</a> at The Chinese University of Hong Kong, supervised by <a href="http://dahua.site/">Prof. Dahua Lin</a>.
              </p>
              <p>
                I got my bachelor's degree from School of Electronic Information and Electrical Engineering at Shanghai Jiao Tong University in 2021, supervised by <a href="https://weiyaolin.github.io/">Prof. Weiyao Lin</a>. 
				During my undergraduate, I also interned at Sensetime OpenMMLab group, supervised by <a href="https://chenkai.site/">Dr. Kai Chen</a>.
				And I am also honored to work with <a href="https://dtaoo.github.io/">Prof. Di Hu</a>.
              </p>
              <p>
                I am interested in computer vision and machine learning, and have done some research on video representation learning and joint audio-visual learning.
              </p>
              <p style="text-align:center">
                <a href="mailto:qr021@ie.cuhk.edu.hk">Email</a> &nbsp/&nbsp
                <a href="data/CV_RuiQian.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/shvdiwnkozbw">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/qianrui.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/qianrui.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>[2022-07]</strong> </b> One paper accepted to <a href="https://eccv2022.ecva.net/">ECCV 2022</a>.
              </p>
              <p>
                <strong>[2022-06]</strong> </b> One paper accepted to <a href="https://2022.acmmm.org/">ACM MM 2022</a>.
              </p>
              <p>
                <strong>[2022-03]</strong> </b> Two papers accepted to <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.
              </p>
              <p>
                <strong>[2021-12]</strong> </b> Two papers accepted to <a href="https://aaai.org/Conferences/AAAI-22/">AAAI 2022</a>.
              </p>
              <p>
                <strong>[2021-07]</strong> </b> One paper accepted to <a href="http://iccv2021.thecvf.com/home">ICCV 2021</a>.
              </p>
              <p>
                <strong>[2021-06]</strong> </b> Graduate from <a href="https://www.sjtu.edu.cn/">Shanghai Jiao Tong University</a>.
              </p>
              <p>
                <strong>[2020-09]</strong> </b> One paper accepted to <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>.
              </p>
              <p>
                <strong>[2020-07]</strong> </b> One paper accepted to <a href="https://eccv2020.eu/">ECCV 2020</a>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/eccv.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Static and Dynamic Concepts for Self-supervised Video Representation Learning</papertitle>
              <br>
              <strong>Rui Qian</strong>, <a href="https://mark12ding.github.io/">Shuangrui Ding</a>, Xian Liu, <a href="http://dahua.site/">Dahua Lin</a>
              <br>
        <em>ECCV</em>, 2022 
              <br>
              More to come. Stay tuned.
              <p></p>
              <p> Learn static and dynamic visual concepts in videos to aggregate local patterns with similar semantics to boost unsupervised video representation.</p>
            </td>
      </tr> 
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MM2022.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Dual Contrastive Learning for Spatio-temporal Representation</papertitle>
              <br>
              <a href="https://mark12ding.github.io/">Shuangrui Ding</a>, <strong>Rui Qian</strong>, <a href="https://min.sjtu.edu.cn/xhk.htm">Hongkai Xiong</a>
              <br>
        <em>ACM MM</em>, 2022 
              <br>
              More to come. Stay tuned.
              <p></p>
              <p> A novel dual contrastive formulation is presented to decouple the static/dynamic features and thus mitigate the background bias.</p>
            </td>
      </tr> 
	  <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/CVPR2022.png' width="200">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Motion-aware Contrastive Video Representation Learning via Foreground-background Merging</papertitle>
              <br>
              <a href="https://mark12ding.github.io/">Shuangrui Ding</a>,
              Maomao Li, Tianyu Yang, <strong>Rui Qian</strong>, Haohang Xu, Qingyi Chen, Jue Wang, <a href="https://min.sjtu.edu.cn/xhk.htm">Hongkai Xiong</a>
              <br>
        <em>CVPR</em>, 2022 
              <br>
              <a href="https://mark12ding.github.io/project/CVPR22_FAME/">Project page</a>,
              <a href="https://arxiv.org/abs/2109.15130/">arXiv</a>,
              <a href="https://github.com/Mark12Ding/FAME">code</a>,
              <a href="https://mp.weixin.qq.com/s/eZ_8qyVa7L8-n2RHBge0mQ">Chinese coverage</a>
              <p></p>
              <p>Mitigate the background bias in self-supervised video representation learning via copy-pasting the foreground onto the other backgrounds.</p>
            </td>
      </tr> 
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/AAAI2022.png' width="200" height="140">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Visual Sound Localization in the Wild by Cross-Modal Interference Erasing</papertitle>
              <br>
              Xian Liu*, <strong>Rui Qian*</strong>, Hang Zhou*, Di Hu, <a href="https://weiyaolin.github.io/">Weiyao Lin</a>, Ziwei Liu, Bolei Zhou, Xiaowei Zhou
              <br>
        <em>AAAI</em>, 2022 
              <br>
              <a href="https://arxiv.org/abs/2202.06406">arXiv</a> / More to come. Stay tuned.
              <p></p>
              <p>Erase the interference in general multi-modal scenes for robust visual sound localization.</p>
            </td>
      </tr> 
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/AAAI2022.JPG' width="200" height="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>TA2N: Two-Stage Action Alignment Network for Few-shot Action Recognition</papertitle>
              <br>
              Shuyuan Li*, Huabin Liu*, <strong>Rui Qian</strong>, Yuxi Li, John See, Mengjuan Fei, Xiaoyuan Yu, <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>AAAI</em>, 2022 
              <br>
              <a href="https://arxiv.org/abs/2107.04782">arXiv</a> / More to come. Stay tuned.
              <p></p>
              <p>Solve action duration misalignment and action evolution misalignment in few-shot settings.</p>
            </td>
      </tr> 

	    <tr onmouseout="iccv_stop()" onmouseover="iccv_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='iccv_image'>
                  <img src='images/iccv2.JPG' width="200" height="120"></div>
                <img src='images/iccv.JPG' width="200" height="120">
              </div>
              <script type="text/javascript">
                function iccv_start() {
                  document.getElementById('iccv_image').style.opacity = "1";
                }

                function iccv_stop() {
                  document.getElementById('iccv_image').style.opacity = "0";
                }
                iccv_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Enhancing Self-supervised Video Representation Learning via Multi-level Feature Optimization</papertitle>
              <br>
			  <strong>Rui Qian</strong>,              
			  Yuxi Li,
			  Huabin Liu,
			  John See,
			  Shuangrui Ding,
			  Xian Liu,
			  Dian Li,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ICCV</em>, 2021  
              <br>
              <a href="https://arxiv.org/abs/2108.02183">arXiv</a>,
			  <a href="https://github.com/shvdiwnkozbw/Video-Representation-via-Multi-level-Optimization">code</a>
			  <p>Self-supervised video representation learning from the perspective of both high-level semantics and lower-level characteristics</p>
			  </td>
          </tr> 
	
	    <tr onmouseout="nips_stop()" onmouseover="nips_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nips_image'>
                  <img src='images/nips2.JPG' width="200" height="150"></div>
                <img src='images/nips.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function nips_start() {
                  document.getElementById('nips_image').style.opacity = "1";
                }

                function nips_stop() {
                  document.getElementById('nips_image').style.opacity = "0";
                }
                nips_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching</papertitle>
              <br>
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  <strong>Rui Qian</strong>,              
			  Minyue Jiang,
			  Tan Xiao,
			  Shilei Wen,
			  Errui Ding,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Dejing Dou
              <br>
        <em>NeurIPS</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2010.05466">arXiv</a>,
			  <a href="https://github.com/DTaoo/Discriminative-Sounding-Objects-Localization">code</a>
			  <p>Discriminative sounding objects localization in cocktail-party scenario in a two-stage manner</p>
			  </td>
          </tr> 


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/eccv2.JPG' width="200" height="150"></div>
                <img src='images/eccv.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Multiple Sound Sources Localization from Coarse to Fine</papertitle>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ECCV</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2007.06355">arXiv</a>,
			  <a href="https://github.com/shvdiwnkozbw/Multi-Source-Sound-Localization">code</a>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 

		  <tr onmouseout="kk_stop()" onmouseover="kk_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='kk_image'>
                  <img src='images/aaai2.JPG' width="200" height="150"></div>
                <img src='images/aaai.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function kk_start() {
                  document.getElementById('kk_image').style.opacity = "1";
                }

                function kk_stop() {
                  document.getElementById('kk_image').style.opacity = "0";
                }
                kk_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
                <papertitle>Finding Action Tubes with a Sparse-to-Dense Framework</papertitle>
              <br>
			  Yuxi Li,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Tao Wang,
			  John See,
              <strong>Rui Qian</strong>,
			  Ning Xu,
			  Limin Wang,
			  Shugong Xu
              <br>
        <em>AAAI</em>, 2020  
              <p>Spatio-temporal action localization, to localize 3D action tubes in temporal and spatial domain</p>
			  </td>
          </tr> 

        </tbody></table>

<!--         <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Workshop Papers</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="cvpr_stop()" onmouseover="cvpr_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                  <img src='images/eccv.JPG' width="200" height="150"></div>
                <img src='images/eccv2.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function cvpr_start() {
                  document.getElementById('cvpr_image').style.opacity = "1";
                }

                function cvpr_stop() {
                  document.getElementById('cvpr_image').style.opacity = "0";
                }
                cvpr_stop()
              </script>
            </td>
	<td style="padding:20px;width:65%;vertical-align:middle">
              <a href="http://sightsound.org/papers/2020/Rui_Qian_A_Two-Stage_Framework_for_Multiple_Sound-Source_Localization.pdf">
                <papertitle>A Two-Stage Framework for Multiple Sound-Source Localization</papertitle>
              </a>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>CVPR Sight and Sound Workshop</em>, 2020  
              <br>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 
 -->		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <strong>Hong Kong PhD Fellowship Scheme</strong>. 2021
              </p>
              <p>
                <strong>Outstanding Graduate of Shanghai</strong>. 2021
              </p>
              <p>
                <strong>Top 1% Bachelor Thesis Award of Shanghai Jiao Tong University</strong>. 2021
              </p>
              <p>
                <strong>Sensetime Scholarship</strong>. 2020
              </p>
              <p>
                <strong>Finalist winner of MCM</strong>. 2019
              </p>
              <p>
              <strong>Nation Scholarship</strong>, Ministry of Education of China. 2018
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Professional Services</heading>
              <p>
                  <li>
                      Reviewer: ICLR 2022, CVPR 2022, ECCV 2022, NeurIPS 2022.
                  </li>
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc</heading>
              <p>
                1. Great honor to be awarded the bachelor's degree from Shanghai Jiao Tong University, really memorable four years and great thanks for the friends, colleagues and professors.
              </p>
              <p>
                2. I am fond of Formula 1 and a real Tifosi. Excited to see Ferrari coming back this season and enjoy the battle between Charles Leclerc and Max Verstappen.
              </p>
			  <p>
				3. Here is my best friend <a href="https://mark12ding.github.io/">Shuangrui</a>, who is really talented and interesting. More than ten years' friendship, great company, marvellous collaboration, memorable encouragement and indispensible shared enjoyment.
			  </p>
            </td>
          </tr>
        </tbody></table>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tbody>
            <tr>
                <td style="padding:0px">
                    <p font-size:small;>
                        <br>
                        <br>
                        <div style="float:left;">
                            Updated at Jul. 2022
                        </div>
                        <div style="float:right;">
                            Thanks <a href="https://jonbarron.info">Jon Barron</a> for this amazing template.
                        </div>
                        <br>
                        <br>        
                    </p>                           
                </td>
            </tr>
        </tbody>
    </table>
    </body>
</html>
