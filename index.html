<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Rui Qian</title>
<meta name="author" content="Rui Qian">
<meta name="viewport" content="width=device-width, initial-scale=1">

<link rel="stylesheet" type="text/css" href="stylesheet.css">
</head>
<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rui Qian (钱锐)</name>
              </p>
              <p>I am a junior undergraduate at Shanghai Jiao Tong University, major in Information Engineering.
              </p>
              <p>
                At SJTU, I have been a member in <a href="http://min.sjtu.edu.cn/">MIN Lab</a>, where I am supervised by <a href="https://weiyaolin.github.io/">Prof. Weiyao Lin</a>. And I am also honored to work with <a href="https://dtaoo.github.io/">Dr. Di Hu</a>.
              </p>
              <p>
                I am interested in computer vision and machine learning, and have done some research on spatio-temporal action localization and joint audio-visual learning. Currently, I would like to explore self-supervised learning for video understanding as well as generative modeling.
              </p>
              <p>
                I am looking forward to pursuing a Ph.D. degree on computer vision and machine learning.  
              </p>
              <p style="text-align:center">
                <a href="mailto:qrui9911@sjtu.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/CV_RuiQian.pdf">CV</a> &nbsp/&nbsp
                <a href="https://github.com/shvdiwnkozbw">Github</a> 
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/QianRui.JPG"><img style="width:100%;max-width:100%" alt="profile photo" src="images/QianRui.JPG" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>News</heading>
              <p>
                <strong>[Sep. 2020]</strong> </b> Our paper <em>Learning to Discriminatively Localize Sounding Objects in a Cocktail-party Scenario</em> was accepted at <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>.
              </p>
              <p>
                <strong>[Jul. 2020]</strong> </b> Our paper <em>ATRW: A Benchmark for Amur Tiger Re-identification in the Wild</em> was accepted at <a href="https://2020.acmmm.org/">ACM MM 2020</a>.
              </p>
              <p>
                <strong>[Jul. 2020]</strong> </b> Our paper <em>Learning to Visually Localize Multiple Sound Sources via A Two-stage Manner</em> was accepted at <a href="https://eccv2020.eu/accepted-papers/">ECCV 2020</a>.
              </p>
			  <p>
                <strong>[Jun. 2020]</strong> </b> Our paper <em>A Two-Stage Framework for Multiple Sound-Source Localization</em> was accepted at <a href="http://sightsound.org/#info">CVPR Sight and Sound Workshop 2020</a>.
			  </p>
			  <p>
                <strong>[May. 2020]</strong> </b> Our challenge <em>HiEve</em> on <a href="http://humaninevents.org/">Large-scale Human-centric Video Analysis in Complex Events</a> at ACM MM 2020 starts.
			  </p>
			  <p>
                <strong>[Nov. 2019]</strong> </b> Our paper <em>Finding Action Tubes with a Sparse-to-Dense Framework</em> was accepted at <a href="http://mcg.nju.edu.cn/publication/2020/AAAI-LiY.5422.pdf">AAAI 2020</a>.
			  </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	    <tr onmouseout="nips_stop()" onmouseover="nips_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nips_image'>
                  <img src='images/nips2.JPG' width="200" height="150"></div>
                <img src='images/nips.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function nips_start() {
                  document.getElementById('nips_image').style.opacity = "1";
                }

                function nips_stop() {
                  document.getElementById('nips_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://neurips.cc/Conferences/2020/AcceptedPapersInitial">
                <papertitle>Discriminative Sounding Objects Localization via Self-supervised Audiovisual Matching</papertitle>
              </a>
              <br>
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  <strong>Rui Qian</strong>,              
			  Minyue Jiang,
			  Tan Xiao,
			  Shilei Wen,
			  Errui Ding,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Dejing Dou
              <br>
        <em>NeurIPS</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2010.05466">arXiv</a>,
			  <a href="https://github.com/DTaoo/Discriminative-Sounding-Objects-Localization">code</a>
			  <p>Discriminative sounding objects localization in cocktail-party scenario in a two-stage manner</p>
			  </td>
          </tr> 


          <tr onmouseout="ff_stop()" onmouseover="ff_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ff_image'>
                  <img src='images/eccv2.JPG' width="200" height="150"></div>
                <img src='images/eccv.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function ff_start() {
                  document.getElementById('ff_image').style.opacity = "1";
                }

                function ff_stop() {
                  document.getElementById('ff_image').style.opacity = "0";
                }
                ff_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://eccv2020.eu/accepted-papers/">
                <papertitle>Multiple Sound Sources Localization from Coarse to Fine</papertitle>
              </a>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>ECCV</em>, 2020  
              <br>
              <a href="https://arxiv.org/abs/2007.06355">arXiv</a>,
			  <a href="https://github.com/shvdiwnkozbw/Multi-Source-Sound-Localization">code</a>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 

		  <tr onmouseout="kk_stop()" onmouseover="kk_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='kk_image'>
                  <img src='images/aaai2.JPG' width="200" height="150"></div>
                <img src='images/aaai.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function kk_start() {
                  document.getElementById('kk_image').style.opacity = "1";
                }

                function kk_stop() {
                  document.getElementById('kk_image').style.opacity = "0";
                }
                kk_stop()
              </script>
            </td>
            <td style="padding:20px;width:65%;vertical-align:middle">
              <a href="https://aaai.org/Papers/AAAI/2020GB/AAAI-LiY.5422.pdf">
                <papertitle>Finding Action Tubes with a Sparse-to-Dense Framework</papertitle>
              </a>
              <br>
			  Yuxi Li,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>,
			  Tao Wang,
			  John See,
              <strong>Rui Qian</strong>,
			  Ning Xu,
			  Limin Wang,
			  Shugong Song
              <br>
        <em>AAAI</em>, 2020  
              <p>Spatio-temporal action localization, to localize 3D action tubes in temporal and spatial domain</p>
			  </td>
          </tr> 

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Workshop Papers</heading>
            </td>
          </tr>
        </tbody></table>
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr onmouseout="cvpr_stop()" onmouseover="cvpr_start()">
            <td style="padding:20px;width:30%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cvpr_image'>
                  <img src='images/eccv.JPG' width="200" height="150"></div>
                <img src='images/eccv2.JPG' width="200" height="150">
              </div>
              <script type="text/javascript">
                function cvpr_start() {
                  document.getElementById('cvpr_image').style.opacity = "1";
                }

                function cvpr_stop() {
                  document.getElementById('cvpr_image').style.opacity = "0";
                }
                cvpr_stop()
              </script>
            </td>
	<td style="padding:20px;width:65%;vertical-align:middle">
              <a href="http://sightsound.org/papers/2020/Rui_Qian_A_Two-Stage_Framework_for_Multiple_Sound-Source_Localization.pdf">
                <papertitle>A Two-Stage Framework for Multiple Sound-Source Localization</papertitle>
              </a>
              <br>
              <strong>Rui Qian</strong>,
              <a href="https://dtaoo.github.io/">Di Hu</a>,
			  Heinrich Dinkel,
			  Mengyue Wu,
			  Ning Xu,
              <a href="https://weiyaolin.github.io/">Weiyao Lin</a>
              <br>
        <em>CVPR Sight and Sound Workshop</em>, 2020  
              <br>
			  <p>Complex audiovisual scene understanding, to associate sound-object pairs from coarse to fine</p>
			  </td>
          </tr> 
		
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Awards</heading>
              <p>
                <strong>Finalist winner</strong> (Top 0.3%), Mathematical Contest in Modeling. 2019
              </p>
              <p>
              <strong>Nation Scholarship</strong> (Top 2%), Ministry of Education of China. 2018
              </p>
            </td>
          </tr>
        </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Misc</heading>
              <p>
                1. I am fond of Formula 1, and a super fan of Scuderia Ferrari, but of course this is a disappointing year because of the lack of competitiveness.
              </p>
              <p>
                2. I am proud that I have graudated from the competition class at Hangzhou No.2 High school, where I make friends with so many talented students and prestigious teachers.
              </p>
			  <p>
				3. Here is my best friend <a href="https://mark12ding.github.io/">Shuangrui</a>, who is really talented and interesting. His wonderful work on adversarial attack on GNN was accepted to <a href="https://nips.cc/Conferences/2020/">NeurIPS 2020</a>!
			  </p>
            </td>
          </tr>
        </tbody></table>
    <p>Updated at Sep. 2020. Thanks <a href="https://jonbarron.info/"> Jon Barron</a> for this amazing template.</p>
    </body>
</html>